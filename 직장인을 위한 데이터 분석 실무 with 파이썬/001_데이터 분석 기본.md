# 001_데이터 분석 기본

---

## pandas

---



```python
import pandas as pd
import numpy as np
```

### 1.데이터 불러오기

```python
'''
sample_1=pd.read_excel('./files/sample_1.xlsx',header=1,usecols='A:C',skipfooter=2,names=['A','B','C'],dtype={'입국객수': np.float64})
sample_1
'''
sample_1=pd.read_excel('C:/Users/nadai/code/data_analyze_with_python/datasalon-master/02_개정판/2_Data_Analysis_Basic/files/sample_1.xlsx',header=1,usecols='A:C',skipfooter=2)
sample_1

sample_1.head()
sample_1.tail()
sample_1.info()
sample_1.dtypes
sample_1.describe()
```

### 2.데이터 선택

```python
sample_1['성별'].value_counts()
sample_1[['국적코드','입국객수']]

sample_1['기준년월']='2019-11'

sample_1[sample_1['성별']=='남성']
condition=(sample_1["입국객수"]>=150000)
sample_1[~condition]
sample_1[(sample_1['성별']=='남성')&condition]

condition_1=sample_1['국적코드']=='A01'
condition_2=sample_1['국적코드']=='A31'
sample_1[condition_1|condition_2]
conditions=(sample_1['국적코드'].isin(['A01','A31']))
sample_1[conditions]
sample_1.loc[1:3,'성별']

code_master=pd.read_excel('C:/Users/nadai/code/data_analyze_with_python/datasalon-master/02_개정판/2_Data_Analysis_Basic/files/sample_codemaster.xlsx')
code_master
```

### 3.데이터 통합-merge

```python
sample_12_code=pd.merge(left=sample_1, right=code_master, how='inner',left_on='국적코드',right_on='국적코드')
sample_13_code=pd.merge(left=sample_1, right=code_master, how='outer',left_on='국적코드',right_on='국적코드')
sample_1_code=pd.merge(left=sample_1, right=code_master, how='left',left_on='국적코드',right_on='국적코드')
print(sample_12_code)
print(sample_13_code)
print(sample_1_code)

sample_2=pd.read_excel('./files/sample_2.xlsx',header=1, skipfooter=2,usecols="A:c")
sample_2['기준년월']='2019-12'
sample_2_code=pd.merge(left=sample_2,right=code_master,how='left',left_on='국적코드',right_on='국적코드')
sample_2_code
```

### 4.데이터 통합-append

```python
sample=sample_1_code.append(sample_2_code, ignore_index=True)
sample
sample_00=sample_1_code.append(sample_2_code, ignore_index=False)
sample_00
```

### 5.데이터 통합-concat

```python
sample_concat=pd.concat([sample_1_code,sample_2_code],ignore_index=True,axis=0)
sample_concat
```

### 6.데이터 저장(to_excel)

```python
sample.to_excel('./files/sample.xlsx',index=False,na_rep='NaN',sheet_name='mysheet')
with pd.ExcelWriter('./files/multiple_sheet.xlsx') as writer:
    sample.to_excel(writer,sheet_name='my_sheet_1')
    sample_1_code.to_excel(writer,sheet_name='my_sheet_2',index=False,na_rep='NaN')
```

### 7.데이터 집계-피벗 데이블

```python
sample_pivot=sample.pivot_table(values='입국객수', index='국적명',columns='기준년월',aggfunc='mean')
sample_pivot
#aggfuc= 'mean','sum','max','min','median','count','nunique'
sample.groupby('성별')['입국객수'].mean()
```

---

## 웹크롤링

---

### 1.selenium과 크롬드라이버 설치

```python
! pip install selenium
X(창닫기)아래-점3개-도움말-크롬정보-크롬버전 확인
https://chromedriver.chromium.org/downloads
```

### 2.크롬드라이버 활용하기

```python
from selenium import webdriver
webdriver.__version__
from selenium.webdriver.chrome.service import Service
ser=Service('../chromedriver/chromedriver.exe')
driver=webdriver.Chrome(service=ser)
```

### 3.웹페이지 접속

```python
url='https://www.naver.com/'
driver.get(url)
#'f12'로 코드 보기
html=driver.page_source
```

### 4.HTML 구조

```python
html='''
<html>
    <head>
    </head>
    <body>
        <h1> 우리동네시장</h1>
            <div class = 'sale'>
                <p id='fruits1' class='fruits'>
                    <span class = 'name'> 바나나 </span>
                    <span class = 'price'> 3000원 </span>
                    <span class = 'inventory'> 500개 </span>
                    <span class = 'store'> 가나다상회 </span>
                    <a href = 'http://bit.ly/forPlaywithData' > 홈페이지 </a>
                </p>
            </div>
            <div class = 'prepare'>
                <p id='fruits2' class='fruits'>
                    <span class ='name'> 파인애플 </span>
                </p>
            </div>
    </body>
</html>'''
#https://opentutorials.org/course/2039 =생활코딩/HTML문법 공부
#-테그와 테그사이 정보가 들어감
#-테그내 속성값을 가질 수 있다.
```

### 5.BeautifulSoup을 이용하여 찾기

```python
'''
! pip install bs4
'''
from bs4 import BeautifulSoup
soup=BeautifulSoup(html,'html.parser')
soup
```

### 6.HTML 정보 찾기
#### 태그명 태그 찾기

```python
tags_sapn=soup.select('span')
print(tags_sapn)
print(len(tags_sapn))
print(type(tags_sapn
tags_p=soup.select('p')
tags_p
```

#### id와 class로 태그 찾기 

```python
#id
soup.select('#fruits1')
#class
soup.select('.price')
soup.select('.inventory')
#tag+class
soup.select('span.name')
```

#### 상위 구조의 활용

```python
soup.select('#fruits1 > span.name')
soup.select('div.sale > #fruits1 > span.name')
soup.select('div.sale span.name')
soup.select('div.sale > p.fruits > span.name')
```

### 7.정보가져오기 

```python
name=soup.select('span.name')
print(name)
name_0=name[0]
name_1=name[1]
print(name_0)
print(name_1)
name_0.text
name_1.text
tags_a=soup.select('a')
type(tags_a) #bs4.element.ResultSet
print(tags_a)
tags_a[0].text
tags_a[0]['href']#링크찾기
```

### 8.실제 네이버에 적용

```python
url='https://www.naver.com/'
driver.get(url)
#'f12'로 코드 보기
html=driver.page_source
soup=BeautifulSoup(html,'html.parser')
soup
```
